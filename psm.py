from playwright.sync_api import sync_playwright
import requests
import time
from datetime import datetime, timedelta
import random
import json
import os
import threading
from http.server import HTTPServer, SimpleHTTPRequestHandler
import locale
from flask import Flask, jsonify, request
from flask_cors import CORS
import collections

# ====================
# SYSTÃˆME DE LOGS POUR L'ADMIN
# ====================
backend_logs = collections.deque(maxlen=200)

def log(message, log_type='info'):
    """Log un message dans la console ET dans backend_logs"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    
    # Afficher dans la console
    print(message)
    
    # Stocker dans la liste
    backend_logs.append({
        'timestamp': timestamp,
        'type': log_type,
        'message': message
    })

# Configuration Playwright pour Docker
os.environ['PLAYWRIGHT_BROWSERS_PATH'] = os.environ.get('PLAYWRIGHT_BROWSERS_PATH', '/root/.cache/ms-playwright')

# Configuration locale pour les dates en franÃ§ais
try:
    locale.setlocale(locale.LC_TIME, 'fr_FR.UTF-8')
except:
    try:
        locale.setlocale(locale.LC_TIME, 'French_France.1252')
    except:
        pass  # Si la locale n'est pas disponible, on utilisera une fonction de remplacement

# ====================
# HISTORIQUE DES DÃ‰TECTIONS PMR
# ====================
DETECTIONS_HISTORY_FILE = 'detections_history.json'

def charger_historique_detections():
    """Charge l'historique des dÃ©tections PMR"""
    try:
        if os.path.exists(DETECTIONS_HISTORY_FILE):
            with open(DETECTIONS_HISTORY_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception as e:
        log(f"âš ï¸ Erreur chargement historique: {e}", 'warning')
    return []

def sauvegarder_detection(match_nom, nb_places):
    """Sauvegarde une dÃ©tection PMR dans l'historique"""
    try:
        historique = charger_historique_detections()
        detection = {
            "match": match_nom,
            "nb_places": nb_places,
            "date": datetime.now().isoformat(),
            "date_formatee": formater_date_francaise(datetime.now())
        }
        historique.append(detection)
        # Garder seulement les 50 derniÃ¨res dÃ©tections
        if len(historique) > 50:
            historique = historique[-50:]
        
        with open(DETECTIONS_HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(historique, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log(f"âš ï¸ Erreur sauvegarde dÃ©tection: {e}", 'warning')

# Charger les matchs depuis le fichier JSON
def charger_matchs():
    try:
        with open('matches.json', 'r', encoding='utf-8') as f:
            matches = json.load(f)
        log(f"ğŸ“‚ matches.json chargÃ©: {len(matches)} match(s)", 'info')
        return matches
    except FileNotFoundError:
        # Matchs par dÃ©faut si le fichier n'existe pas
        matchs_default = [
    {
        "nom": "PSG vs PARIS FC",
        "url": "https://billetterie.psg.fr/fr/catalogue/match-foot-masculin-paris-sg-vs-paris-fc-1"
    },
    {
        "nom": "PSG vs RENNE",
        "url": "https://billetterie.psg.fr/fr/catalogue/match-foot-masculin-paris-vs-rennes-5"
            }
        ]
        with open('matches.json', 'w', encoding='utf-8') as f:
            json.dump(matchs_default, f, ensure_ascii=False, indent=2)
        log(f"ğŸ“‚ matches.json crÃ©Ã© avec {len(matchs_default)} match(s) par dÃ©faut", 'info')
        return matchs_default

# ====================
# FONCTIONS HELPER POUR GROQ
# ====================

def extract_teams_from_match_name(match_name):
    """Extrait les Ã©quipes depuis le nom du match"""
    # Format attendu: "PSG vs OM" ou "PSG vs PARIS FC"
    parts = match_name.split(' vs ')
    if len(parts) == 2:
        return {'home': parts[0].strip(), 'away': parts[1].strip()}
    return {'home': 'PSG', 'away': 'Adversaire'}

def detect_match_importance(home_team, away_team, match_name):
    """DÃ©tecte l'importance du match"""
    away_lower = away_team.lower()
    match_lower = match_name.lower()
    
    is_classico = 'classique' in match_lower or (home_team == 'PSG' and ('om' in away_lower or 'marseille' in away_lower))
    is_ol = 'lyon' in away_lower or 'ol' in away_lower
    is_monaco = 'monaco' in away_lower
    is_high_profile = is_classico or is_ol or is_monaco
    
    return {
        'is_classico': is_classico,
        'is_ol': is_ol,
        'is_monaco': is_monaco,
        'is_high_profile': is_high_profile,
        'rivalry': 'Le Classique' if is_classico else ('Grande affiche' if is_ol else ('Match attractif' if is_monaco else 'Match rÃ©gulier'))
    }

def get_comparison_matches(match_name, home_team, limit=3):
    """RÃ©cupÃ¨re les VRAIS autres matchs depuis matches.json pour la comparaison"""
    try:
        matches_data = charger_matchs()  # Utiliser la fonction existante
        
        # Filtrer les matchs : mÃªme Ã©quipe Ã  domicile, exclure le match actuel
        comparison_matches = []
        for match in matches_data:
            match_nom = match.get('nom', '')
            # VÃ©rifier que c'est un match Ã  domicile de la mÃªme Ã©quipe
            if home_team in match_nom and match_nom != match_name:
                # Extraire l'Ã©quipe adverse
                parts = match_nom.split(' vs ')
                if len(parts) == 2 and parts[0].strip() == home_team:
                    away_team = parts[1].strip()
                    comparison_matches.append({
                        'name': match_nom,
                        'away_team': away_team,
                        'url': match.get('url', ''),
                        'key': f'match_{len(comparison_matches) + 1}'
                    })
        
        # Si pas assez de matchs rÃ©els, complÃ©ter avec des matchs estimÃ©s
        if len(comparison_matches) < limit:
            fallback_matches = [
                {'name': f'{home_team} vs Lyon', 'key': 'match_fallback_1'},
                {'name': f'{home_team} vs Monaco', 'key': 'match_fallback_2'},
                {'name': f'{home_team} vs Lens', 'key': 'match_fallback_3'}
            ]
            # Exclure ceux qui sont dÃ©jÃ  dans comparison_matches
            for fallback in fallback_matches:
                if len(comparison_matches) >= limit:
                    break
                away_lower = fallback['name'].split(' vs ')[1].lower()
                if not any(away_lower in m['name'].lower() for m in comparison_matches):
                    if match_name.lower() not in fallback['name'].lower():
                        comparison_matches.append(fallback)
        
        return comparison_matches[:limit]
    except Exception as e:
        log(f"âš ï¸ Erreur rÃ©cupÃ©ration matchs de comparaison: {e}", 'warning')
        # Fallback avec matchs par dÃ©faut
        return [
            {'name': f'{home_team} vs Lyon', 'key': 'match_1'},
            {'name': f'{home_team} vs Monaco', 'key': 'match_2'},
            {'name': f'{home_team} vs Lens', 'key': 'match_3'}
        ]

# ====================
# SYSTÃˆME DE CACHE GROQ
# ====================
GROQ_CACHE_FILE = 'groq_cache.json'

def get_cached_groq_data(match_name):
    """RÃ©cupÃ¨re les donnÃ©es en cache si elles existent et sont rÃ©centes (< 24h)"""
    try:
        with open(GROQ_CACHE_FILE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
        
        if match_name in cache:
            cached_data = cache[match_name]
            last_updated = datetime.fromisoformat(cached_data.get('last_updated', '2000-01-01'))
            hours_diff = (datetime.now() - last_updated).total_seconds() / 3600
            
            if hours_diff < 24:
                log(f"âœ… DonnÃ©es Groq en cache pour {match_name} ({hours_diff:.1f}h)", 'info')
                return cached_data
            else:
                log(f"â° Cache expirÃ© pour {match_name} ({hours_diff:.1f}h)", 'info')
    except FileNotFoundError:
        pass
    except Exception as e:
        log(f"âš ï¸ Erreur lecture cache: {e}", 'warning')
    
    return None

def save_groq_cache(match_name, data):
    """Sauvegarde les donnÃ©es dans le cache"""
    try:
        cache = {}
        if os.path.exists(GROQ_CACHE_FILE):
            with open(GROQ_CACHE_FILE, 'r', encoding='utf-8') as f:
                cache = json.load(f)
        
        cache[match_name] = data
        cache[match_name]['last_updated'] = datetime.now().isoformat()
        
        with open(GROQ_CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(cache, f, ensure_ascii=False, indent=2)
        
        log(f"ğŸ’¾ Cache Groq sauvegardÃ© pour {match_name}", 'info')
    except Exception as e:
        log(f"âš ï¸ Erreur sauvegarde cache: {e}", 'warning')

# âœ… LISTE DES MATCHS Ã€ SURVEILLER (chargÃ©e dynamiquement)
MATCHS = charger_matchs()

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN", "8222793392:AAFBtlCNAlPyUYgf1aup06HAvRO9V14DmRo")
CHAT_ID = os.getenv("TELEGRAM_CHAT_ID", "-1003428870741")

# Cooldown par match
dernier_message_indispo = {}

# Statistiques pour le status.json
nb_checks_par_match = {}
dernier_check_par_match = {}
pmr_disponible_par_match = {}

# Mois en franÃ§ais
MOIS_FR = {
    1: "janvier", 2: "fÃ©vrier", 3: "mars", 4: "avril",
    5: "mai", 6: "juin", 7: "juillet", 8: "aoÃ»t",
    9: "septembre", 10: "octobre", 11: "novembre", 12: "dÃ©cembre"
}

def formater_date_francaise(dt):
    """Formate une date en franÃ§ais avec le mois en lettres"""
    jour = dt.day
    mois = MOIS_FR[dt.month]
    annee = dt.year
    heure = dt.strftime("%H:%M:%S")
    return f"{jour} {mois} {annee} Ã  {heure}"

def envoyer_message(msg):
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    data = {"chat_id": CHAT_ID, "text": msg}
    try:
        r = requests.post(url, data=data, timeout=10)
        print("Telegram:", r.text)
    except Exception as e:
        print("Erreur Telegram:", e)

def sauvegarder_status():
    """Sauvegarde l'Ã©tat du bot dans status.json pour le site web"""
    status = {
        "bot_actif": True,
        "derniere_mise_a_jour": formater_date_francaise(datetime.now()),
        "matchs": []
    }
    
    total_checks = 0
    alertes_envoyees = 0
    
    for match in MATCHS:
        nom = match["nom"]
        
        # Calculer le temps depuis le dernier check
        if nom in dernier_check_par_match:
            dernier_check = dernier_check_par_match[nom]
            diff = datetime.now() - dernier_check
            minutes = int(diff.total_seconds() / 60)
            if minutes < 1:
                dernier_check_str = "Ã€ l'instant"
            elif minutes == 1:
                dernier_check_str = "Il y a 1 min"
            else:
                dernier_check_str = f"Il y a {minutes} min"
        else:
            dernier_check_str = "En attente..."
        
        # RÃ©cupÃ©rer les statistiques
        nb_checks = nb_checks_par_match.get(nom, 0)
        pmr_dispo = pmr_disponible_par_match.get(nom, False)
        total_checks += nb_checks
        
        # Compter les alertes (quand PMR Ã©tait disponible)
        if pmr_dispo:
            alertes_envoyees += 1
        
        status["matchs"].append({
            "nom": nom,
            "url": match["url"],
            "pmr_disponible": pmr_dispo,
            "dernier_check": dernier_check_str,
            "nb_checks": nb_checks
        })
    
    # Calculer le taux de disponibilitÃ© (pourcentage de fois oÃ¹ PMR Ã©tait disponible)
    nb_matchs = len(MATCHS)
    if nb_matchs > 0:
        matchs_avec_pmr = sum(1 for match in MATCHS if pmr_disponible_par_match.get(match["nom"], False))
        taux_disponibilite = round((matchs_avec_pmr / nb_matchs) * 100, 1)
    else:
        taux_disponibilite = 0.0
    
    # Ajouter les statistiques globales
    status["statistiques"] = {
        "verifications_totales": total_checks,
        "alertes_envoyees": alertes_envoyees,
        "taux_disponibilite": f"{taux_disponibilite}%",
        "matchs_surveilles": nb_matchs
    }
    
    import os
    status_path = 'status.json'
    with open(status_path, 'w', encoding='utf-8') as f:
        json.dump(status, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ status.json sauvegardÃ© dans: {os.path.abspath(status_path)}")

def verifier_match(match):
    nom = match["nom"]
    url = match["url"]

    if nom not in dernier_message_indispo:
        dernier_message_indispo[nom] = datetime.now() - timedelta(hours=8)

    try:
        with sync_playwright() as p:
            # Configuration pour Docker/headless
            browser = p.chromium.launch(
                headless=True,
                args=[
                    '--no-sandbox',
                    '--disable-setuid-sandbox',
                    '--disable-dev-shm-usage',
                    '--disable-gpu',
                    '--disable-software-rasterizer',
                    '--disable-extensions',
                    '--window-size=1920x1080',
                    '--disable-blink-features=AutomationControlled',
                    '--disable-features=IsolateOrigins,site-per-process',
                    '--single-process',
                    '--no-zygote'
                ],
                timeout=60000
            )
            
            context = browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            )
            
            page = context.new_page()
            
            # Configuration des timeouts plus longs
            page.set_default_timeout(120000)  # 120 secondes pour toutes les opÃ©rations
            page.set_default_navigation_timeout(120000)

            log(f"ğŸŒ Chargement de {nom}...", 'info')
            try:
                page.goto(url, timeout=120000, wait_until="domcontentloaded")
                log(f"âœ… Page chargÃ©e pour {nom}", 'success')
            except Exception as goto_error:
                log(f"âš ï¸ Erreur lors du chargement de la page pour {nom}: {goto_error}", 'warning')
                log(f"ğŸ”„ Nouvelle tentative...", 'info')
                page.goto(url, timeout=120000, wait_until="domcontentloaded")
                log(f"âœ… Page chargÃ©e pour {nom} (2Ã¨me tentative)", 'success')
            
            # Attendre BEAUCOUP plus longtemps que le contenu se charge
            log(f"â³ Attente du chargement complet...", 'info')
            page.wait_for_timeout(10000)  # 10 secondes au lieu de 4
            
            # Scroll AVANT de chercher les Ã©lÃ©ments
            log(f"ğŸ“œ Scroll de la page...", 'info')
            for i in range(5):  # Plus de scrolls
                page.mouse.wheel(0, 1500)
                page.wait_for_timeout(2000)  # Plus de temps entre chaque scroll
            
            # Attendre encore aprÃ¨s le scroll
            page.wait_for_timeout(5000)
            
            # Essayer de cliquer sur un bouton si prÃ©sent (pour dÃ©clencher le chargement)
            try:
                page.wait_for_selector('button, .button, [role="button"]', timeout=5000)
            except:
                pass

            heure = datetime.now().strftime("%H:%M:%S")

            pmr_elements = page.query_selector_all('div[data-offer-type="PMR"]')
            log(f"{nom} â†’ PMR trouvÃ©es : {len(pmr_elements)}", 'info')
            
            # Sauvegarder la dÃ©tection si des PMR sont trouvÃ©es
            if len(pmr_elements) > 0:
                sauvegarder_detection(nom, len(pmr_elements))

            # Mettre Ã  jour les statistiques
            nb_checks_par_match[nom] = nb_checks_par_match.get(nom, 0) + 1
            dernier_check_par_match[nom] = datetime.now()
            pmr_disponible_par_match[nom] = len(pmr_elements) > 0

            if len(pmr_elements) > 0:
                envoyer_message(f"ğŸ”¥ ALERTE PLACE PMR DISPONIBLE ! ğŸ”¥\n\nğŸŸï¸ Match : {nom}\nâœ… Places PMR trouvÃ©es !\n\nğŸ‘‰ Fonce sur la billetterie maintenant !")
            else:
                if datetime.now() - dernier_message_indispo[nom] >= timedelta(hours=8):
                    envoyer_message(f"ğŸ˜´ Pas encore de places PMR...\n\nğŸŸï¸ Match : {nom}\nâŒ Aucune place PMR disponible pour le moment\n\nğŸ’ª On continue de surveiller pour toi !")
                    dernier_message_indispo[nom] = datetime.now()
                else:
                    log(f"{nom} â†’ Pas de PMR (cooldown actif)", 'info')

            # Sauvegarder le status avant de fermer
            sauvegarder_status()

            context.close()
            browser.close()

    except Exception as e:
        log(f"âš ï¸ Erreur sur {nom} : {e}", 'error')
        import traceback
        log(f"ğŸ“‹ DÃ©tails de l'erreur :", 'error')
        traceback.print_exc()
        # Sauvegarder le status mÃªme en cas d'erreur
        sauvegarder_status()

# CrÃ©er le fichier status.json initial
sauvegarder_status()

# ====================
# API FLASK
# ====================
app = Flask(__name__)
# DÃ©sactiver CORS dans Flask car le serveur web le gÃ¨re dÃ©jÃ 
# Cela Ã©vite les conflits de headers CORS multiples
CORS(app, resources={r"/api/*": {"origins": "*", "supports_credentials": False}})

# Chemins des fichiers
MATCHES_FILE = 'matches.json'
ANALYTICS_FILE = 'analytics.json'

@app.route('/api/status', methods=['GET'])
def api_get_status():
    """Retourne le statut complet du bot depuis status.json"""
    try:
        with open('status.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
        return jsonify(data)
    except FileNotFoundError:
        return jsonify({"error": "Status file not found"}), 404
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/matches', methods=['GET'])
def api_get_matches():
    """Liste tous les matchs surveillÃ©s"""
    try:
        with open(MATCHES_FILE, 'r', encoding='utf-8') as f:
            matches = json.load(f)
        return jsonify(matches)
    except FileNotFoundError:
        # Si le fichier n'existe pas, le crÃ©er avec les matchs par dÃ©faut
        default_matches = charger_matchs()
        return jsonify(default_matches)

@app.route('/api/matches', methods=['POST'])
def api_add_match():
    """Ajoute un nouveau match Ã  surveiller"""
    try:
        data = request.json
        nom = data.get('nom', '').strip()
        url = data.get('url', '').strip()
        
        # Validation
        if not nom or not url:
            return jsonify({"error": "Nom et URL requis"}), 400
        
        # Validation de l'URL
        try:
            from urllib.parse import urlparse
            parsed = urlparse(url)
            if not parsed.scheme or not parsed.netloc:
                return jsonify({"error": "URL invalide. Veuillez entrer une URL complÃ¨te (ex: https://...)"}), 400
        except Exception:
            return jsonify({"error": "URL invalide"}), 400
        
        # Lire les matchs existants
        try:
            with open(MATCHES_FILE, 'r', encoding='utf-8') as f:
                matches = json.load(f)
        except FileNotFoundError:
            matches = []
        
        # VÃ©rifier si le match existe dÃ©jÃ 
        for match in matches:
            if match.get('nom') == nom:
                return jsonify({"error": f"Un match avec le nom '{nom}' existe dÃ©jÃ "}), 409
            if match.get('url') == url:
                return jsonify({"error": f"Un match avec cette URL existe dÃ©jÃ "}), 409
        
        # Ajouter le nouveau match
        new_match = {"nom": nom, "url": url}
        matches.append(new_match)
        
        # Sauvegarder
        with open(MATCHES_FILE, 'w', encoding='utf-8') as f:
            json.dump(matches, f, ensure_ascii=False, indent=2)
        
        # Mettre Ã  jour status.json immÃ©diatement
        global MATCHS
        MATCHS = matches  # Mettre Ã  jour la variable globale
        sauvegarder_status()  # Mettre Ã  jour status.json pour que le site l'affiche
        
        log(f"âœ… Match ajoutÃ©: {nom} ({url})", 'success')
        log(f"ğŸ“Š Total de matchs surveillÃ©s: {len(matches)}", 'info')
        log(f"ğŸ”„ Le match sera vÃ©rifiÃ© au prochain cycle de surveillance (~90 secondes)", 'info')
        log(f"ğŸ’¾ matches.json mis Ã  jour avec succÃ¨s", 'success')
        log(f"ğŸ’¾ status.json mis Ã  jour - le nouveau match apparaÃ®t sur le site public", 'success')
        
        return jsonify({"success": True, "match": new_match}), 201
    except Exception as e:
        print(f"âŒ Erreur ajout match: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

@app.route('/api/matches/<int:index>', methods=['DELETE'])
def api_delete_match(index):
    """Supprime un match par son index"""
    try:
        with open(MATCHES_FILE, 'r', encoding='utf-8') as f:
            matches = json.load(f)
        
        if 0 <= index < len(matches):
            deleted = matches.pop(index)
            
            # Sauvegarder
            with open(MATCHES_FILE, 'w', encoding='utf-8') as f:
                json.dump(matches, f, ensure_ascii=False, indent=2)
            
            # Mettre Ã  jour status.json immÃ©diatement
            global MATCHS
            MATCHS = matches  # Mettre Ã  jour la variable globale
            sauvegarder_status()  # Mettre Ã  jour status.json
            
            log(f"ğŸ—‘ï¸ Match supprimÃ©: {deleted.get('nom')} ({deleted.get('url')})", 'error')
            log(f"ğŸ“Š Matchs restants: {len(matches)}", 'info')
            log(f"ğŸ’¾ matches.json mis Ã  jour avec succÃ¨s", 'success')
            log(f"ğŸ’¾ status.json mis Ã  jour - le site public reflÃ¨te le changement", 'success')
            log(f"â¸ï¸ Le match ne sera plus surveillÃ© au prochain cycle", 'info')
            
            return jsonify({"success": True, "deleted": deleted})
        else:
            return jsonify({"error": "Index invalide"}), 404
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/matches/<int:index>/check', methods=['POST'])
def api_force_check(index):
    """Force la vÃ©rification d'un match spÃ©cifique"""
    try:
        # Charger les matchs
        try:
            with open(MATCHES_FILE, 'r', encoding='utf-8') as f:
                matches = json.load(f)
        except FileNotFoundError:
            matches = charger_matchs()
        
        # VÃ©rifier que l'index est valide
        if 0 <= index < len(matches):
            match = matches[index]
            nom = match.get("nom", "Match inconnu")
            
            # Lancer la vÃ©rification dans un thread sÃ©parÃ© pour ne pas bloquer
            def verifier_en_background():
                url_match = match.get("url", "URL inconnue")
                log(f"ğŸ”„ VÃ©rification forcÃ©e de {nom}...", 'info')
                log(f"ğŸŒ URL: {url_match}", 'info')
                verifier_match(match)
                log(f"âœ… VÃ©rification forcÃ©e de {nom} terminÃ©e", 'success')
            
            threading.Thread(target=verifier_en_background, daemon=True).start()
            
            return jsonify({
                "success": True, 
                "message": f"VÃ©rification de {nom} lancÃ©e en arriÃ¨re-plan"
            })
        else:
            return jsonify({"error": "Index invalide"}), 404
    except Exception as e:
        print(f"âŒ Erreur vÃ©rification forcÃ©e: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

@app.route('/api/analytics', methods=['GET'])
def api_get_analytics():
    """Retourne les statistiques du site web"""
    try:
        with open(ANALYTICS_FILE, 'r', encoding='utf-8') as f:
            analytics = json.load(f)
        
        # S'assurer que toutes les propriÃ©tÃ©s existent
        default_values = {
            "visiteurs_totaux": 0,
            "visiteurs_en_ligne": 0,
            "visiteurs_aujourdhui": 0,
            "temps_moyen": "0m 0s",
            "taux_rebond": "0%",
            "clics_telegram": 0,
            "pic_connexions": 0,
            "taux_retour": "0%",
            "historique_7j": [0, 0, 0, 0, 0, 0, 0],
            "derniere_date": None
        }
        
        # Remplir les valeurs manquantes
        for key, default_value in default_values.items():
            if key not in analytics:
                analytics[key] = default_value
        
        # VÃ©rifier si l'historique doit Ãªtre mis Ã  jour (nouveau jour)
        date_actuelle = datetime.now().strftime("%Y-%m-%d")
        derniere_date = analytics.get("derniere_date")
        
        if derniere_date != date_actuelle and derniere_date is not None:
            # Nouveau jour dÃ©tectÃ©, mettre Ã  jour l'historique
            try:
                derniere_date_obj = datetime.strptime(derniere_date, "%Y-%m-%d")
                date_actuelle_obj = datetime.strptime(date_actuelle, "%Y-%m-%d")
                jours_ecoules = (date_actuelle_obj - derniere_date_obj).days
                
                if jours_ecoules > 0:
                    # DÃ©caler l'historique
                    for i in range(min(jours_ecoules, 7)):
                        analytics["historique_7j"].pop(0)
                        analytics["historique_7j"].append(0)
                    
                    if jours_ecoules >= 7:
                        analytics["historique_7j"] = [0, 0, 0, 0, 0, 0, 0]
                    
                    analytics["visiteurs_aujourdhui"] = 0
                    analytics["derniere_date"] = date_actuelle
                    
                    # Sauvegarder la mise Ã  jour
                    with open(ANALYTICS_FILE, 'w', encoding='utf-8') as f:
                        json.dump(analytics, f, ensure_ascii=False, indent=2)
            except Exception as e:
                print(f"âš ï¸ Erreur mise Ã  jour historique: {e}")
        
        return jsonify(analytics)
    except FileNotFoundError:
        # CrÃ©er des stats par dÃ©faut (valeurs rÃ©elles, pas de simulation)
        default_analytics = {
            "visiteurs_totaux": 0,
            "visiteurs_en_ligne": 0,
            "visiteurs_aujourdhui": 0,
            "temps_moyen": "0m 0s",
            "taux_rebond": "0%",
            "clics_telegram": 0,
            "pic_connexions": 0,
            "taux_retour": "0%",
            "historique_7j": [0, 0, 0, 0, 0, 0, 0],
            "derniere_date": datetime.now().strftime("%Y-%m-%d")
        }
        with open(ANALYTICS_FILE, 'w', encoding='utf-8') as f:
            json.dump(default_analytics, f, ensure_ascii=False, indent=2)
        return jsonify(default_analytics)
    except Exception as e:
        print(f"âŒ Erreur lecture analytics: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

@app.route('/api/analytics/visitor', methods=['POST'])
def api_track_visitor():
    """Enregistre une visite sur le site"""
    try:
        # Charger analytics
        try:
            with open(ANALYTICS_FILE, 'r', encoding='utf-8') as f:
                analytics = json.load(f)
        except FileNotFoundError:
            # Initialiser avec toutes les propriÃ©tÃ©s nÃ©cessaires
            analytics = {
                "visiteurs_totaux": 0,
                "visiteurs_en_ligne": 0,
                "visiteurs_aujourdhui": 0,
                "temps_moyen": "0m 0s",
                "taux_rebond": "0%",
                "clics_telegram": 0,
                "pic_connexions": 0,
                "taux_retour": "0%",
                "historique_7j": [0, 0, 0, 0, 0, 0, 0],
                "derniere_date": None
            }
        
        # S'assurer que toutes les propriÃ©tÃ©s existent
        if "visiteurs_totaux" not in analytics:
            analytics["visiteurs_totaux"] = 0
        if "visiteurs_en_ligne" not in analytics:
            analytics["visiteurs_en_ligne"] = 0
        if "visiteurs_aujourdhui" not in analytics:
            analytics["visiteurs_aujourdhui"] = 0
        if "temps_moyen" not in analytics:
            analytics["temps_moyen"] = "0m 0s"
        if "taux_rebond" not in analytics:
            analytics["taux_rebond"] = "0%"
        if "clics_telegram" not in analytics:
            analytics["clics_telegram"] = 0
        if "pic_connexions" not in analytics:
            analytics["pic_connexions"] = 0
        if "taux_retour" not in analytics:
            analytics["taux_retour"] = "0%"
        if "historique_7j" not in analytics:
            analytics["historique_7j"] = [0, 0, 0, 0, 0, 0, 0]
        if "derniere_date" not in analytics:
            analytics["derniere_date"] = None
        
        # Obtenir la date actuelle (format YYYY-MM-DD)
        date_actuelle = datetime.now().strftime("%Y-%m-%d")
        derniere_date = analytics.get("derniere_date")
        
        # Si c'est un nouveau jour, mettre Ã  jour l'historique
        if derniere_date != date_actuelle:
            if derniere_date is not None:
                # Calculer le nombre de jours Ã©coulÃ©s
                try:
                    derniere_date_obj = datetime.strptime(derniere_date, "%Y-%m-%d")
                    date_actuelle_obj = datetime.strptime(date_actuelle, "%Y-%m-%d")
                    jours_ecoules = (date_actuelle_obj - derniere_date_obj).days
                    
                    # Si plus d'un jour s'est Ã©coulÃ©, dÃ©caler l'historique
                    if jours_ecoules > 0:
                        # DÃ©caler l'historique vers la gauche
                        for i in range(min(jours_ecoules, 7)):
                            analytics["historique_7j"].pop(0)
                            analytics["historique_7j"].append(0)
                        
                        # Si plus de 7 jours, rÃ©initialiser
                        if jours_ecoules >= 7:
                            analytics["historique_7j"] = [0, 0, 0, 0, 0, 0, 0]
                except Exception as e:
                    print(f"âš ï¸ Erreur calcul jours: {e}")
                    # En cas d'erreur, rÃ©initialiser l'historique
                    analytics["historique_7j"] = [0, 0, 0, 0, 0, 0, 0]
            
            # RÃ©initialiser le compteur du jour actuel
            analytics["visiteurs_aujourdhui"] = 0
            analytics["derniere_date"] = date_actuelle
        
        # IncrÃ©menter les compteurs
        analytics["visiteurs_totaux"] = analytics.get("visiteurs_totaux", 0) + 1
        analytics["visiteurs_en_ligne"] = analytics.get("visiteurs_en_ligne", 0) + 1
        analytics["visiteurs_aujourdhui"] = analytics.get("visiteurs_aujourdhui", 0) + 1
        
        # Mettre Ã  jour l'historique des 7 derniers jours (dernier Ã©lÃ©ment = aujourd'hui)
        if len(analytics["historique_7j"]) > 0:
            analytics["historique_7j"][-1] = analytics["visiteurs_aujourdhui"]
        else:
            analytics["historique_7j"] = [analytics["visiteurs_aujourdhui"]]
        
        # Mettre Ã  jour le pic de connexions si nÃ©cessaire
        if analytics["visiteurs_en_ligne"] > analytics.get("pic_connexions", 0):
            analytics["pic_connexions"] = analytics["visiteurs_en_ligne"]
        
        # Sauvegarder
        with open(ANALYTICS_FILE, 'w', encoding='utf-8') as f:
            json.dump(analytics, f, ensure_ascii=False, indent=2)
        
        return jsonify({"success": True})
    except Exception as e:
        print(f"âŒ Erreur tracking visiteur: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

@app.route('/api/detections-history', methods=['GET'])
def api_get_detections_history():
    """Retourne l'historique des dÃ©tections PMR"""
    try:
        historique = charger_historique_detections()
        # Filtrer par match si spÃ©cifiÃ©
        match_filter = request.args.get('match')
        if match_filter:
            historique = [d for d in historique if match_filter.lower() in d.get('match', '').lower()]
        return jsonify(historique)
    except Exception as e:
        log(f"âŒ Erreur rÃ©cupÃ©ration historique: {e}", 'error')
        return jsonify({"error": str(e)}), 500

@app.route('/api/analytics/telegram-click', methods=['POST'])
def api_track_telegram_click():
    """Enregistre un clic sur le bouton Telegram"""
    try:
        # Charger analytics
        try:
            with open(ANALYTICS_FILE, 'r', encoding='utf-8') as f:
                analytics = json.load(f)
        except FileNotFoundError:
            # Initialiser avec toutes les propriÃ©tÃ©s nÃ©cessaires
            analytics = {
                "visiteurs_totaux": 0,
                "visiteurs_en_ligne": 0,
                "visiteurs_aujourdhui": 0,
                "temps_moyen": "0m 0s",
                "taux_rebond": "0%",
                "clics_telegram": 0,
                "pic_connexions": 0,
                "taux_retour": "0%",
                "historique_7j": [0, 0, 0, 0, 0, 0, 0]
            }
        
        # S'assurer que toutes les propriÃ©tÃ©s existent
        if "clics_telegram" not in analytics:
            analytics["clics_telegram"] = 0
        
        # IncrÃ©menter
        analytics["clics_telegram"] = analytics.get("clics_telegram", 0) + 1
        
        # Sauvegarder
        with open(ANALYTICS_FILE, 'w', encoding='utf-8') as f:
            json.dump(analytics, f, ensure_ascii=False, indent=2)
        
        return jsonify({"success": True})
    except Exception as e:
        print(f"âŒ Erreur tracking clic Telegram: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

@app.route('/api/logs', methods=['GET'])
def api_get_logs():
    """Retourne les logs du backend"""
    try:
        limit = request.args.get('limit', 50, type=int)
        logs = list(backend_logs)[-limit:]  # Derniers N logs
        return jsonify({
            "success": True,
            "logs": logs,
            "total": len(backend_logs)
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/groq/analyze', methods=['GET'])
def api_groq_analyze():
    """GÃ©nÃ¨re une analyse IA complÃ¨te du match avec Groq (analysis, comparison, weather, lineups)"""
    try:
        match_name = request.args.get('match')
        if not match_name:
            return jsonify({"error": "ParamÃ¨tre 'match' requis"}), 400
        
        # VÃ©rifier le cache d'abord
        cached_data = get_cached_groq_data(match_name)
        if cached_data:
            return jsonify(cached_data)
        
        # Charger les donnÃ©es du match depuis status.json
        try:
            with open('status.json', 'r', encoding='utf-8') as f:
                status = json.load(f)
        except FileNotFoundError:
            return jsonify({"error": "status.json non trouvÃ©"}), 404
        
        match = next((m for m in status.get('matchs', []) if m['nom'] == match_name), None)
        if not match:
            return jsonify({"error": "Match non trouvÃ©"}), 404
        
        # Charger les donnÃ©es complÃ¨tes du match depuis matches.json
        matches_list = charger_matchs()
        match_data = next((m for m in matches_list if m.get('nom') == match_name), None)
        
        # Extraire les Ã©quipes
        teams = extract_teams_from_match_name(match_name)
        home_team = teams['home']
        away_team = teams['away']
        
        # DÃ©tecter l'importance
        importance = detect_match_importance(home_team, away_team, match_name)
        
        # RÃ©cupÃ©rer les VRAIS matchs de comparaison depuis matches.json
        comparison_matches = get_comparison_matches(match_name, home_team, limit=3)
        
        # Utiliser les donnÃ©es du match si disponibles, sinon laisser Groq gÃ©nÃ©rer
        if match_data and match_data.get('date') and match_data.get('time'):
            # Formater la date depuis le format ISO (YYYY-MM-DD)
            match_date_obj = datetime.strptime(match_data['date'], '%Y-%m-%d')
            jours_semaine = ['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche']
            jour_semaine = jours_semaine[match_date_obj.weekday()]
            mois_fr = MOIS_FR[match_date_obj.month]
            date_formatted_fr = f"{jour_semaine} {match_date_obj.day} {mois_fr.capitalize()} {match_date_obj.year}"
            time_formatted = match_data.get('time', '21:00')
            competition = match_data.get('competition', 'Ligue 1')
            lieu = match_data.get('lieu', 'Parc des Princes')
            use_match_data = True
        else:
            # Pas de donnÃ©es, laisser Groq gÃ©nÃ©rer
            current_date = datetime.now()
            saison_info = f"Saison 2024-2025, nous sommes actuellement en {MOIS_FR[current_date.month].capitalize()} {current_date.year}"
            use_match_data = False
        
        # Construire la section comparaison
        if comparison_matches:
            comparison_section = f"""
2. COMPARAISON AVEC AUTRES MATCHS DE {home_team}:
   
   Analyse ET compare "{match_name}" avec ces matchs RÃ‰ELS du calendrier :
   
   {chr(10).join([f'   {i+1}. {m["name"]}' for i, m in enumerate(comparison_matches)])}
   
   Pour CHAQUE match ci-dessus, analyse son importance et donne un score d'anticipation (0-100).
   RÃ¨gles:
   - {home_team}-OM (Le Classique) = toujours le plus haut (90-100)
   - {home_team}-Lyon = trÃ¨s attractif (80-92)
   - {home_team}-Monaco = attractif (75-88)
   - Autres Ã©quipes = variable selon classement (60-80)
   
   Compare "{match_name}" avec ces matchs et classe-les par importance.
   Retourne les scores pour:
   - current_match: score de "{match_name}"
   {chr(10).join([f'   - {m["key"]}: score de "{m["name"]}"' for m in comparison_matches])}
"""
        else:
            comparison_section = f"""
2. COMPARAISON AVEC AUTRES MATCHS:
   GÃ©nÃ¨re des scores estimÃ©s pour 3 autres matchs importants de {home_team}:
   - match_1: {home_team} vs Lyon (grand rival)
   - match_2: {home_team} vs Monaco (affiche attractive)
   - match_3: {home_team} vs Lens (match moyen)
"""
        
        # Construire les parties du prompt qui contiennent des backslashes
        psg_lineup_text = '- Utilise les vrais joueurs du PSG actuel: Donnarumma (GK), Hakimi, Marquinhos (C), Skriniar, Mendes (DF), Vitinha, ZaÃ¯re-Emery, Ugarte (MF), DembÃ©lÃ©, Ramos, Barcola (FW)'
        om_lineup_text = "- Utilise les vrais joueurs de l'OM actuel: LÃ³pez (GK), Clauss, Gigot, Balerdi, Tavares (DF), Rongier, Veretout, Harit (MF), Aubameyang, Greenwood, Moumbagna (FW)"
        
        home_lineup_instruction = psg_lineup_text if home_team == 'PSG' else f'- Utilise les vrais joueurs actuels de {home_team}'
        away_lineup_instruction = om_lineup_text if ('OM' in away_team or 'Marseille' in away_team) else f'- Utilise les vrais joueurs actuels de {away_team}'
        
        # Construire la partie comparaison (sans backslash dans les expressions)
        comparison_json_lines = []
        comparison_name_lines = []
        if comparison_matches:
            for m in comparison_matches:
                comparison_json_lines.append(f'    "{m["key"]}": number,')
                comparison_name_lines.append(f'    "{m["key"]}_name": "{m["name"]}",')
        else:
            comparison_json_lines = ['    "match_1": number,', '    "match_2": number,', '    "match_3": number,']
        
        # Construire les chaÃ®nes de comparaison
        comparison_json_str = '\n'.join(comparison_json_lines)
        comparison_name_str = '\n'.join(comparison_name_lines) if comparison_name_lines else ''
        
        # Construire les parties du prompt avec des conditions
        importance_text = 'Match Ã  trÃ¨s forte affluence' if importance['is_high_profile'] else 'Match d\'importance moyenne'
        classico_text = 'Le Classique PSG-OM gÃ©nÃ¨re toujours une demande exceptionnelle (90-100%).' if importance['is_classico'] else ''
        ol_text = 'PSG-OL est une affiche majeure de Ligue 1 (80-95%).' if importance['is_ol'] else ''
        monaco_text = 'PSG-Monaco est un match attractif (75-90%).' if importance['is_monaco'] else ''
        other_text = 'Pour un match moins mÃ©diatisÃ©, ajuste les scores en consÃ©quence (60-85%).' if not importance['is_high_profile'] else ''
        
        # Construire le template JSON sÃ©parÃ©ment
        json_template = """{{
  "match_info": {{
    "competition": "string (ex: Ligue 1, Coupe de France, Ligue des Champions)",
    "match_type": "string (ex: Le Classique, Derby, Match de championnat, etc.)",
    "date_formatted": "string (format: 'Dimanche 15 Janvier 2025')",
    "time": "string (format: '21:00')"
  }},
  "analysis": {{
    "hype_score": number,
    "affluence_prevue": number,
    "probabilite_pmr": number,
    "analyse": "string adaptÃ©e Ã  """ + match_name + """"
  }},
  "comparison": {{
    "current_match": number,
""" + comparison_json_str + """
""" + comparison_name_str + """
  }},
  "weather": {{
    "temperature": number,
    "condition": "string",
    "rain_chance": number,
    "wind_speed": number,
    "emoji": "string"
  }},
  "lineups": {{
    "home": {{
      "formation": "string",
      "gk": ["string"],
      "df": ["string", "string", "string", "string"],
      "mf": ["string", "string", "string"],
      "fw": ["string", "string", "string"]
    }},
    "away": {{
      "formation": "string",
      "gk": ["string"],
      "df": ["string", "string", "string", "string"],
      "mf": ["string", "string", "string"],
      "fw": ["string", "string", "string"]
    }}
  }}
}}"""
        
        # Construire le prompt complet en concatÃ©nant les parties
        prompt = f"""Tu es un expert en football franÃ§ais, mÃ©tÃ©orologie, analyse de donnÃ©es sportives ET accessibilitÃ© pour personnes Ã  mobilitÃ© rÃ©duite.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CONTEXTE DE L'APPLICATION ET DU SITE WEB
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Cette analyse est gÃ©nÃ©rÃ©e pour un site web dÃ©diÃ© Ã  la surveillance des places PMR (Personnes Ã  MobilitÃ© RÃ©duite) pour les matchs du PSG au Parc des Princes.

PROBLÃˆME RÃ‰SOLU PAR L'APPLICATION:
- Les places PMR au Parc des Princes sont EXTÃŠMEMENT rares et difficiles Ã  obtenir
- La billetterie PSG met ces places en vente de maniÃ¨re alÃ©atoire et imprÃ©visible
- Les places partent en quelques minutes, parfois secondes
- Les personnes en situation de handicap doivent surveiller la billetterie 24/7 pour ne pas rater une opportunitÃ©
- C'est un vrai parcours du combattant pour obtenir une place PMR

FONCTIONNEMENT DU BOT:
- Un bot automatisÃ© surveille la billetterie PSG en continu (toutes les ~90 secondes)
- Il dÃ©tecte automatiquement quand des places PMR se libÃ¨rent
- Il envoie une alerte Telegram instantanÃ©e dÃ¨s qu'une place est disponible
- Le bot a dÃ©jÃ  effectuÃ© {match.get('nb_checks', 0)} vÃ©rifications pour ce match
- Statut actuel: {'âœ… Places PMR DISPONIBLES' if match.get('pmr_disponible', False) else 'âŒ Aucune place PMR disponible pour le moment'}

LE SITE WEB:
- Site public accessible Ã  tous pour voir l'Ã©tat de la surveillance en temps rÃ©el
- Affiche pour chaque match: disponibilitÃ© PMR, nombre de vÃ©rifications, dernier check
- Interface admin pour gÃ©rer les matchs surveillÃ©s
- Analytics de frÃ©quentation et d'utilisation
- Cette page "more.html" affiche une analyse dÃ©taillÃ©e du match avec:
  * Analyse IA de l'anticipation et probabilitÃ© de disponibilitÃ© PMR
  * Comparaison avec d'autres matchs du calendrier
  * MÃ©tÃ©o prÃ©vue pour le jour du match
  * Compositions probables des Ã©quipes
  * Historique des dÃ©tections PMR pour ce match

PUBLIC CIBLE:
- Personnes en situation de handicap (fauteuil roulant, mobilitÃ© rÃ©duite)
- Accompagnants de personnes Ã  mobilitÃ© rÃ©duite
- Supporters PSG qui ont besoin d'un accÃ¨s PMR
- CommunautÃ© qui s'entraide pour obtenir ces places rares

IMPORTANCE DES PLACES PMR:
- Les places PMR sont limitÃ©es (quelques dizaines par match maximum)
- Pour les gros matchs (Classique, OL, Monaco), la demande est Ã©norme
- Les places se libÃ¨rent souvent au dernier moment (annulations, dÃ©sistements)
- Obtenir une place PMR peut prendre des semaines de surveillance
- C'est un enjeu d'accessibilitÃ© et d'inclusion sociale

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MATCH Ã€ ANALYSER
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

- Ã‰quipes: {match_name}
- Stade: Parc des Princes (capacitÃ© ~48 000 places, places PMR trÃ¨s limitÃ©es)
- Contexte temporel: {saison_info}
- Contexte: {importance['rivalry']}
- Importance: {importance_text}
- Nombre de vÃ©rifications effectuÃ©es: {match.get('nb_checks', 0)}
- Statut PMR actuel: {'âœ… DISPONIBLE - Le bot a dÃ©tectÃ© des places PMR !' if match.get('pmr_disponible', False) else 'âŒ Non disponible - Le bot continue de surveiller'}
- Historique: Le bot surveille ce match depuis le dÃ©but, vÃ©rifiant rÃ©guliÃ¨rement la disponibilitÃ©

INFORMATIONS Ã€ GÃ‰NÃ‰RER (section match_info):
{f"- competition: Utilise '{competition}' (dÃ©jÃ  fournie)" if use_match_data else "- competition: DÃ©termine la compÃ©tition (Ligue 1, Coupe de France, Ligue des Champions, etc.)"}
- match_type: DÃ©termine le type de match selon l'adversaire:
  * "Le Classique" pour PSG vs OM
  * "Derby" pour PSG vs PARIS FC
  * "Affiche" pour PSG vs OL, Monaco, etc.
  * "Match de championnat" pour les autres Ã©quipes
{f"- date_formatted: Utilise '{date_formatted_fr}' (dÃ©jÃ  fournie)" if use_match_data else "- date_formatted: GÃ©nÃ¨re une date RÃ‰ALISTE et FUTURE pour ce match selon le calendrier de la Ligue 1. La date doit Ãªtre dans le futur. Format franÃ§ais complet avec jour de la semaine (ex: 'Dimanche 15 Janvier 2025'). IMPORTANT: GÃ©nÃ¨re une date DIFFÃ‰RENTE pour chaque match, pas toujours la mÃªme !"}
{f"- time: Utilise '{time_formatted}' (dÃ©jÃ  fournie)" if use_match_data else "- time: Heure du match au format 24h (ex: '21:00'). Les matchs de Ligue 1 sont gÃ©nÃ©ralement Ã  17:00, 19:00, 21:00 ou 15:00. Les Classiques sont souvent Ã  21:00 (prime time). IMPORTANT: GÃ©nÃ¨re une heure DIFFÃ‰RENTE pour chaque match, pas toujours la mÃªme !"}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CONSIGNES D'ANALYSE DÃ‰TAILLÃ‰E ET CONTEXTUALISÃ‰E
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. ANALYSE D'ANTICIPATION APPROFONDIE ET CONTEXTUALISÃ‰E:
   Analyse en profondeur le niveau d'attente pour ce match spÃ©cifique "{match_name}" EN TENANT COMPTE:
   - Du contexte de l'application (surveillance PMR, raretÃ© des places)
   - De l'importance du match pour les supporters
   - De la demande spÃ©cifique pour les places PMR (diffÃ©rente de la demande gÃ©nÃ©rale)
   - Du fait que les places PMR sont encore plus rares que les places normales
   
   {classico_text}
   {ol_text}
   {monaco_text}
   {other_text}
   
   IMPORTANT: Adapte ton analyse au CONTEXTE PMR:
   - Les places PMR ont une demande diffÃ©rente (plus stable, moins impulsive)
   - Les personnes en situation de handicap planifient souvent longtemps Ã  l'avance
   - Les gros matchs gÃ©nÃ¨rent une demande PMR encore plus forte (accÃ¨s rare = trÃ¨s recherchÃ©)
   - Les matchs moins mÃ©diatisÃ©s peuvent avoir des places PMR plus facilement disponibles
   
   - hype_score: niveau d'anticipation supporters (0-100) - Justifie avec des Ã©lÃ©ments concrets liÃ©s au contexte PMR
   - affluence_prevue: taux de remplissage estimÃ© (0-100) - Base-toi sur l'historique du Parc des Princes
   - probabilite_pmr: chance qu'une place PMR se libÃ¨re (0-100) - CONSIDÃˆRE:
     * La raretÃ© extrÃªme des places PMR (beaucoup plus rare que places normales)
     * Le fait que {match.get('nb_checks', 0)} vÃ©rifications ont Ã©tÃ© faites sans rÃ©sultat (si 0, c'est nouveau)
     * L'importance du match (gros match = probabilitÃ© plus faible)
     * Le timing (plus on approche du match, plus c'est rare)
   - analyse: explication TRÃˆS DÃ‰TAILLÃ‰E (7-10 phrases) incluant:
     * Contexte du match (rivalitÃ©, enjeux, importance) adaptÃ© au public PMR
     * Historique des places PMR pour ce type de match (raretÃ©, difficultÃ© d'obtention)
     * Facteurs influenÃ§ant la disponibilitÃ© PMR (demande, timing, saison, importance)
     * Recommandations CONCRÃˆTES pour l'utilisateur (activer alertes Telegram, surveiller rÃ©guliÃ¨rement, etc.)
     * ProbabilitÃ© dÃ©taillÃ©e avec justification basÃ©e sur le contexte PMR
     * Encouragement et conseils pratiques pour obtenir une place
     * Mention de l'utilitÃ© du bot pour ne pas rater une opportunitÃ©

1. ANALYSE D'ANTICIPATION APPROFONDIE:
   Analyse en profondeur le niveau d'attente pour ce match spÃ©cifique "{match_name}".
   {classico_text}
   {ol_text}
   {monaco_text}
   {other_text}
   
   - hype_score: niveau d'anticipation supporters (0-100) - Justifie avec des Ã©lÃ©ments concrets liÃ©s au contexte PMR
   - affluence_prevue: taux de remplissage estimÃ© (0-100) - Base-toi sur l'historique du Parc des Princes
   - probabilite_pmr: chance qu'une place PMR se libÃ¨re (0-100) - CONSIDÃˆRE:
     * La raretÃ© extrÃªme des places PMR (beaucoup plus rare que places normales)
     * Le fait que {match.get('nb_checks', 0)} vÃ©rifications ont Ã©tÃ© faites sans rÃ©sultat (si 0, c'est nouveau)
     * L'importance du match (gros match = probabilitÃ© plus faible)
     * Le timing (plus on approche du match, plus c'est rare)
   - analyse: explication TRÃˆS DÃ‰TAILLÃ‰E (7-10 phrases) incluant:
     * Contexte du match (rivalitÃ©, enjeux, importance) adaptÃ© au public PMR
     * Historique des places PMR pour ce type de match (raretÃ©, difficultÃ© d'obtention)
     * Facteurs influenÃ§ant la disponibilitÃ© PMR (demande, timing, saison, importance)
     * Recommandations CONCRÃˆTES pour l'utilisateur (activer alertes Telegram, surveiller rÃ©guliÃ¨rement, etc.)
     * ProbabilitÃ© dÃ©taillÃ©e avec justification basÃ©e sur le contexte PMR
     * Encouragement et conseils pratiques pour obtenir une place
     * Mention de l'utilitÃ© du bot pour ne pas rater une opportunitÃ©

{comparison_section}

3. MÃ‰TÃ‰O PRÃ‰VUE DÃ‰TAILLÃ‰E:
   Pour Parc des Princes Ã  la date que tu auras gÃ©nÃ©rÃ©e dans match_info.date_formatted:
   - Utilise des donnÃ©es mÃ©tÃ©o rÃ©alistes pour Paris/France Ã  cette pÃ©riode
   - En janvier: gÃ©nÃ©ralement 5-10Â°C, souvent nuageux, risque de pluie moyen
   - En Ã©tÃ©: 20-30Â°C, plutÃ´t ensoleillÃ©
   - Adapte selon la saison rÃ©elle
   
   - temperature: tempÃ©rature en Â°C (cohÃ©rente avec la date)
   - condition: description dÃ©taillÃ©e ("EnsoleillÃ© avec quelques nuages", "Nuageux avec averses possibles", etc.)
   - rain_chance: probabilitÃ© de pluie (0-100) avec justification
   - wind_speed: vitesse vent en km/h (10-20 km/h typique)
   - emoji: emoji mÃ©tÃ©o appropriÃ© (â˜€ï¸, ğŸŒ¤ï¸, â›…, ğŸŒ§ï¸, â›ˆï¸, etc.)

4. COMPOSITIONS PROBABLES DÃ‰TAILLÃ‰ES:
   GÃ©nÃ¨re les compositions RÃ‰ALISTES et ACTUELLES (saison 2024-2025):
   
   Pour {home_team}:
   {home_lineup_instruction}
   - Formation: 4-3-3 (typique) ou autre selon le contexte
   - Inclus les vrais noms de joueurs actuels
   
   Pour {away_team}:
   {away_lineup_instruction}
   - Formation: 4-3-3 ou autre selon le contexte
   - Inclus les vrais noms de joueurs actuels

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
INSTRUCTIONS FINALES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

IMPORTANT - RÃˆGLES STRICTES:
- Analyse TRÃˆS DÃ‰TAILLÃ‰E avec justification de chaque score basÃ©e sur le CONTEXTE PMR
- Adapte TOUS les scores et analyses au match spÃ©cifique "{match_name}"
- Ne copie JAMAIS les valeurs d'un autre match
- Sois cohÃ©rent: PSG-OM > PSG-OL > PSG-Monaco > PSG-Ã©quipe moyenne (pour la demande PMR)
- Utilise les vrais effectifs 2024-2025 avec noms rÃ©els de joueurs
- MÃ©tÃ©o rÃ©aliste et dÃ©taillÃ©e pour la date gÃ©nÃ©rÃ©e dans match_info.date_formatted Ã  Paris
- L'analyse textuelle doit faire 7-10 phrases minimum avec dÃ©tails concrets
- TON PROFESSIONNEL: Sois empathique, encourageant, et pratique pour les personnes en situation de handicap
- Mentionne l'utilitÃ© du bot de surveillance et des alertes Telegram
- Sois rÃ©aliste sur la raretÃ© des places PMR mais encourageant sur les possibilitÃ©s

CONTEXTE Ã€ GARDER EN TÃŠTE:
- Cette analyse sera lue par des personnes qui ont besoin d'une place PMR
- Elles comptent sur cette analyse pour comprendre leurs chances
- Le bot les aide Ã  ne pas rater une opportunitÃ©
- C'est un enjeu d'accessibilitÃ© et d'inclusion

RÃ©ponds UNIQUEMENT avec ce JSON, sans texte avant/aprÃ¨s, sans markdown:
""" + json_template

        # ClÃ© API Groq (doit Ãªtre dÃ©finie dans les variables d'environnement)
        GROQ_API_KEY = os.getenv("GROQ_API_KEY")
        if not GROQ_API_KEY:
            log("âš ï¸ GROQ_API_KEY non dÃ©finie, impossible de gÃ©nÃ©rer l'analyse", 'warning')
            return jsonify({"error": "GROQ_API_KEY non configurÃ©e"}), 500
        
        GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"
        
        log(f"ğŸ“¡ Appel API Groq pour {match_name}", 'info')
        log(f"ğŸ”‘ GROQ_API_KEY prÃ©sente: {'Oui' if GROQ_API_KEY else 'Non'}", 'info')
        log(f"ğŸ”— URL API: {GROQ_API_URL}", 'info')
        
        # Appeler l'API Groq
        headers = {
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "llama-3.3-70b-versatile",
            "messages": [
                {
                    "role": "system",
                    "content": "Tu es un expert en football franÃ§ais, mÃ©tÃ©orologie et analyse de donnÃ©es sportives. RÃ©ponds UNIQUEMENT avec du JSON valide, sans markdown, sans code blocks."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.4,
            "max_tokens": 1500,
            "top_p": 0.9
        }
        
        log(f"ğŸ“¤ Payload envoyÃ© - Model: {payload['model']}, Messages: {len(payload['messages'])}", 'info')
        log(f"ğŸ“ Taille du prompt: {len(prompt)} caractÃ¨res", 'info')
        
        try:
            response = requests.post(GROQ_API_URL, json=payload, headers=headers, timeout=30)
            log(f"ğŸ“¥ RÃ©ponse Groq reÃ§ue - Status: {response.status_code}", 'info')
        except requests.exceptions.Timeout:
            log(f"â±ï¸ Timeout lors de l'appel API Groq (30s dÃ©passÃ©)", 'error')
            raise
        except requests.exceptions.RequestException as e:
            log(f"âŒ Erreur rÃ©seau lors de l'appel API Groq: {e}", 'error')
            raise
        
        if response.status_code != 200:
            error_detail = ""
            try:
                error_response = response.json()
                error_detail = f" - {error_response.get('error', {}).get('message', str(error_response))}"
            except:
                error_detail = f" - {response.text[:500]}"
            log(f"âŒ Erreur API Groq: {response.status_code}{error_detail}", 'error')
            log(f"ğŸ“„ RÃ©ponse complÃ¨te (premiers 1000 caractÃ¨res): {response.text[:1000]}", 'error')
            # Retourner des donnÃ©es par dÃ©faut au lieu d'une erreur 500
            default_data = {
                "analysis": {
                    "hype_score": 75,
                    "affluence_prevue": 85,
                    "probabilite_pmr": 15,
                    "analyse": f"Le match {match_name} a Ã©tÃ© vÃ©rifiÃ© {match.get('nb_checks', 0)} fois. BasÃ© sur l'historique, la probabilitÃ© de disponibilitÃ© de places PMR est modÃ©rÃ©e. Recommandation : activer les alertes Telegram pour ne pas manquer une opportunitÃ©."
                },
                "comparison": {
                    "current_match": 75,
                    "match_1": 70,
                    "match_1_name": comparison_matches[0]['name'] if comparison_matches else f"{home_team} vs Lyon",
                    "match_2": 65,
                    "match_2_name": comparison_matches[1]['name'] if len(comparison_matches) > 1 else f"{home_team} vs Monaco",
                    "match_3": 60,
                    "match_3_name": comparison_matches[2]['name'] if len(comparison_matches) > 2 else f"{home_team} vs Lens"
                },
                "weather": {
                    "temperature": 12,
                    "condition": "Variable",
                    "rain_chance": 30,
                    "wind_speed": 15,
                    "emoji": "ğŸŒ¤ï¸"
                },
                "lineups": {
                    "home": {
                        "formation": "4-3-3",
                        "gk": ["Gardien"],
                        "df": ["DF1", "DF2", "DF3", "DF4"],
                        "mf": ["MF1", "MF2", "MF3"],
                        "fw": ["FW1", "FW2", "FW3"]
                    },
                    "away": {
                        "formation": "4-3-3",
                        "gk": ["Gardien"],
                        "df": ["DF1", "DF2", "DF3", "DF4"],
                        "mf": ["MF1", "MF2", "MF3"],
                        "fw": ["FW1", "FW2", "FW3"]
                    }
                },
                "last_updated": datetime.now().isoformat(),
                "error": True
            }
            save_groq_cache(match_name, default_data)
            return jsonify(default_data)
        
        result = response.json()
        log(f"âœ… RÃ©ponse JSON parsÃ©e avec succÃ¨s", 'info')
        log(f"ğŸ“Š Nombre de choix: {len(result.get('choices', []))}", 'info')
        
        if 'choices' not in result or len(result['choices']) == 0:
            raise ValueError("Aucun choix dans la rÃ©ponse Groq")
        
        content = result['choices'][0]['message']['content']
        content_original = content  # Sauvegarder pour les logs d'erreur
        log(f"ğŸ“ Contenu brut reÃ§u (premiers 500 caractÃ¨res): {content[:500]}", 'info')
        log(f"ğŸ“ Taille du contenu: {len(content)} caractÃ¨res", 'info')
        
        # Parser le JSON de la rÃ©ponse
        try:
            # Nettoyer le contenu (enlever markdown si prÃ©sent)
            content = content.strip()
            if content.startswith('```json'):
                content = content[7:]
            if content.startswith('```'):
                content = content[3:]
            if content.endswith('```'):
                content = content[:-3]
            content = content.strip()
            
            # Extraire le JSON
            json_match = None
            if '{' in content:
                start = content.find('{')
                end = content.rfind('}') + 1
                json_match = content[start:end]
            
            if not json_match:
                raise ValueError("Aucun JSON trouvÃ© dans la rÃ©ponse")
            
            complete_data = json.loads(json_match)
            
            # VÃ©rifier que toutes les sections sont prÃ©sentes
            required_keys = ['match_info', 'analysis', 'comparison', 'weather', 'lineups']
            if not all(key in complete_data for key in required_keys):
                missing = [k for k in required_keys if k not in complete_data]
                raise ValueError(f"DonnÃ©es incomplÃ¨tes dans la rÃ©ponse Groq. Sections manquantes: {missing}")
            
            # Ajouter timestamp
            complete_data['last_updated'] = datetime.now().isoformat()
            
            # Logger la rÃ©ponse Groq complÃ¨te de maniÃ¨re structurÃ©e
            log(f"âœ… RÃ©ponse Groq reÃ§ue pour {match_name}", 'info')
            
            # Logger chaque section sÃ©parÃ©ment pour plus de lisibilitÃ©
            if 'analysis' in complete_data:
                analysis = complete_data['analysis']
                log(f"ğŸ“Š Analyse IA - Hype: {analysis.get('hype_score', 'N/A')}% | Affluence: {analysis.get('affluence_prevue', 'N/A')}% | ProbabilitÃ© PMR: {analysis.get('probabilite_pmr', 'N/A')}%", 'info')
                log(f"ğŸ’­ Analyse dÃ©taillÃ©e: {analysis.get('analyse', 'N/A')[:200]}...", 'info')
            
            if 'comparison' in complete_data:
                comp = complete_data['comparison']
                log(f"ğŸ“ˆ Comparaison - Match actuel: {comp.get('current_match', 'N/A')}%", 'info')
            
            if 'weather' in complete_data:
                weather = complete_data['weather']
                log(f"ğŸŒ¤ï¸ MÃ©tÃ©o - {weather.get('temperature', 'N/A')}Â°C | {weather.get('condition', 'N/A')} | Pluie: {weather.get('rain_chance', 'N/A')}% | Vent: {weather.get('wind_speed', 'N/A')} km/h", 'info')
            
            if 'lineups' in complete_data:
                lineups = complete_data['lineups']
                home_form = lineups.get('home', {}).get('formation', 'N/A')
                away_form = lineups.get('away', {}).get('formation', 'N/A')
                log(f"âš½ Compositions - Domicile: {home_form} | ExtÃ©rieur: {away_form}", 'info')
            
            # Logger le JSON complet pour rÃ©fÃ©rence (formatÃ©)
            log(f"ğŸ“‹ JSON Groq complet:\n{json.dumps(complete_data, ensure_ascii=False, indent=2)}", 'info')
            
            # Sauvegarder dans le cache
            save_groq_cache(match_name, complete_data)
            
            return jsonify(complete_data)
            
        except (json.JSONDecodeError, ValueError) as e:
            # Si le parsing Ã©choue, retourner des donnÃ©es par dÃ©faut
            log(f"âš ï¸ RÃ©ponse Groq invalide, utilisation de valeurs par dÃ©faut: {e}", 'warning')
            log(f"ğŸ“„ Contenu original (premiers 1000 caractÃ¨res): {content_original[:1000]}", 'warning')
            log(f"ğŸ“„ Contenu nettoyÃ© (premiers 1000 caractÃ¨res): {content[:1000]}", 'warning')
            if json_match:
                log(f"ğŸ“„ JSON extrait (premiers 1000 caractÃ¨res): {json_match[:1000]}", 'warning')
            default_data = {
                "analysis": {
                    "hype_score": 75,
                    "affluence_prevue": 85,
                    "probabilite_pmr": 15,
                    "analyse": f"Le match {match_name} a Ã©tÃ© vÃ©rifiÃ© {match.get('nb_checks', 0)} fois. BasÃ© sur l'historique, la probabilitÃ© de disponibilitÃ© de places PMR est modÃ©rÃ©e. Recommandation : activer les alertes Telegram pour ne pas manquer une opportunitÃ©."
                },
                "comparison": {
                    "current_match": 75,
                    "match_1": 70,
                    "match_1_name": comparison_matches[0]['name'] if comparison_matches else f"{home_team} vs Lyon",
                    "match_2": 65,
                    "match_2_name": comparison_matches[1]['name'] if len(comparison_matches) > 1 else f"{home_team} vs Monaco",
                    "match_3": 60,
                    "match_3_name": comparison_matches[2]['name'] if len(comparison_matches) > 2 else f"{home_team} vs Lens"
                },
                "weather": {
                    "temperature": 12,
                    "condition": "Variable",
                    "rain_chance": 30,
                    "wind_speed": 15,
                    "emoji": "ğŸŒ¤ï¸"
                },
                "lineups": {
                    "home": {
                        "formation": "4-3-3",
                        "gk": ["Gardien"],
                        "df": ["DF1", "DF2", "DF3", "DF4"],
                        "mf": ["MF1", "MF2", "MF3"],
                        "fw": ["FW1", "FW2", "FW3"]
                    },
                    "away": {
                        "formation": "4-3-3",
                        "gk": ["Gardien"],
                        "df": ["DF1", "DF2", "DF3", "DF4"],
                        "mf": ["MF1", "MF2", "MF3"],
                        "fw": ["FW1", "FW2", "FW3"]
                    }
                },
                "last_updated": datetime.now().isoformat(),
                "error": True
            }
            save_groq_cache(match_name, default_data)
            return jsonify(default_data)
            
    except Exception as e:
        log(f"âŒ Erreur analyse Groq: {e}", 'error')
        import traceback
        traceback.print_exc()
        # Retourner des donnÃ©es par dÃ©faut au lieu d'une erreur 500
        try:
            match_name = request.args.get('match', 'Match inconnu')
            teams = extract_teams_from_match_name(match_name)
            home_team = teams['home']
            comparison_matches = get_comparison_matches(match_name, home_team, limit=3)
        except:
            home_team = 'PSG'
            comparison_matches = []
        
        default_data = {
            "analysis": {
                "hype_score": 75,
                "affluence_prevue": 85,
                "probabilite_pmr": 15,
                "analyse": f"Erreur lors de la gÃ©nÃ©ration de l'analyse IA. DonnÃ©es par dÃ©faut affichÃ©es."
            },
            "comparison": {
                "current_match": 75,
                "match_1": 70,
                "match_1_name": comparison_matches[0]['name'] if comparison_matches else f"{home_team} vs Lyon",
                "match_2": 65,
                "match_2_name": comparison_matches[1]['name'] if len(comparison_matches) > 1 else f"{home_team} vs Monaco",
                "match_3": 60,
                "match_3_name": comparison_matches[2]['name'] if len(comparison_matches) > 2 else f"{home_team} vs Lens"
            },
            "weather": {
                "temperature": 12,
                "condition": "Variable",
                "rain_chance": 30,
                "wind_speed": 15,
                "emoji": "ğŸŒ¤ï¸"
            },
            "lineups": {
                "home": {
                    "formation": "4-3-3",
                    "gk": ["Gardien"],
                    "df": ["DF1", "DF2", "DF3", "DF4"],
                    "mf": ["MF1", "MF2", "MF3"],
                    "fw": ["FW1", "FW2", "FW3"]
                },
                "away": {
                    "formation": "4-3-3",
                    "gk": ["Gardien"],
                    "df": ["DF1", "DF2", "DF3", "DF4"],
                    "mf": ["MF1", "MF2", "MF3"],
                    "fw": ["FW1", "FW2", "FW3"]
                }
            },
            "last_updated": datetime.now().isoformat(),
            "error": True
        }
        return jsonify(default_data)

def start_flask_api():
    """DÃ©marre l'API Flask dans un thread sÃ©parÃ©"""
    app.run(host='0.0.0.0', port=5000, debug=False, use_reloader=False)

# DÃ©marrer l'API Flask en arriÃ¨re-plan
threading.Thread(target=start_flask_api, daemon=True).start()
log("ğŸ”Œ API Flask dÃ©marrÃ©e sur le port 5000", 'success')

# DÃ©marrer le serveur web dans un thread sÃ©parÃ©
def start_web_server():
    """Serveur web simple pour servir index.html et status.json"""
    port = 8081  # Port diffÃ©rent du site pour Ã©viter les conflits
    
    class CustomHandler(SimpleHTTPRequestHandler):
        def __init__(self, *args, **kwargs):
            super().__init__(*args, directory='Site', **kwargs)
        
        def end_headers(self):
            # Ajouter les headers CORS pour permettre l'accÃ¨s depuis n'importe oÃ¹
            self.send_header('Access-Control-Allow-Origin', '*')
            self.send_header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS, DELETE')
            self.send_header('Access-Control-Allow-Headers', '*')
            super().end_headers()
        
        def do_OPTIONS(self):
            """GÃ©rer les requÃªtes OPTIONS pour CORS"""
            self.send_response(200)
            self.end_headers()
        
        def _proxy_to_flask(self, method='GET'):
            """Proxy les requÃªtes /api/* vers Flask sur le port 5000"""
            import urllib.request
            import urllib.parse
            
            try:
                # Construire l'URL Flask
                flask_url = f'http://localhost:5000{self.path}'
                log(f"ğŸ”„ Proxy: {method} {self.path} â†’ {flask_url}", 'info')
                
                # PrÃ©parer la requÃªte
                req_data = None
                if method == 'POST' or method == 'PUT' or method == 'DELETE':
                    content_length = int(self.headers.get('Content-Length', 0))
                    if content_length > 0:
                        req_data = self.rfile.read(content_length)
                
                # CrÃ©er la requÃªte
                req = urllib.request.Request(flask_url, data=req_data, method=method)
                
                # Copier les headers
                for header, value in self.headers.items():
                    if header.lower() not in ['host', 'content-length']:
                        req.add_header(header, value)
                
                # Faire la requÃªte
                with urllib.request.urlopen(req, timeout=30) as response:
                    status_code = response.getcode()
                    log(f"âœ… Proxy rÃ©ponse: {status_code} pour {self.path}", 'info')
                    # Envoyer la rÃ©ponse
                    self.send_response(status_code)
                    # Copier les headers de Flask SAUF les headers CORS (on les gÃ¨re nous-mÃªmes)
                    for header, value in response.headers.items():
                        header_lower = header.lower()
                        if header_lower not in ['connection', 'transfer-encoding', 
                                                'access-control-allow-origin', 
                                                'access-control-allow-methods',
                                                'access-control-allow-headers',
                                                'access-control-allow-credentials']:
                            self.send_header(header, value)
                    # Les headers CORS seront ajoutÃ©s par end_headers()
                    self.end_headers()
                    self.wfile.write(response.read())
                    
            except urllib.error.HTTPError as e:
                log(f"âŒ Erreur HTTP proxy Flask: {e.code} {e.reason} pour {self.path}", 'error')
                self.send_response(e.code)
                self.send_header('Content-type', 'application/json')
                self.end_headers()
                try:
                    error_body = e.read().decode('utf-8')
                    log(f"ğŸ“„ Corps erreur HTTP: {error_body[:500]}", 'error')
                    self.wfile.write(error_body.encode('utf-8'))
                except:
                    error_msg = json.dumps({"error": f"Proxy HTTP error: {e.code} {e.reason}"})
                    self.wfile.write(error_msg.encode('utf-8'))
            except urllib.error.URLError as e:
                log(f"âŒ Erreur URL proxy Flask: {e.reason} pour {self.path}", 'error')
                self.send_response(502)
                self.send_header('Content-type', 'application/json')
                self.end_headers()
                error_msg = json.dumps({"error": f"Proxy URL error: {str(e)}"})
                self.wfile.write(error_msg.encode('utf-8'))
            except Exception as e:
                log(f"âŒ Erreur proxy Flask: {type(e).__name__}: {e} pour {self.path}", 'error')
                import traceback
                log(f"ğŸ“‹ Traceback: {traceback.format_exc()}", 'error')
                self.send_response(502)
                self.send_header('Content-type', 'application/json')
                self.end_headers()
                error_msg = json.dumps({"error": f"Proxy error: {str(e)}"})
                self.wfile.write(error_msg.encode('utf-8'))
        
        def do_GET(self):
            # Si c'est une requÃªte API, proxy vers Flask
            if self.path.startswith('/api/'):
                self._proxy_to_flask('GET')
                return
            
            # Si on demande status.json, le servir depuis la racine du projet
            if self.path == '/status.json' or self.path == '/status.json/':
                import os
                # status.json est dans le WORKDIR (/app)
                # Utiliser le chemin absolu depuis le rÃ©pertoire de travail
                status_path = os.path.join(os.getcwd(), 'status.json')
                print(f"ğŸ” Tentative de servir status.json depuis: {status_path}")
                print(f"ğŸ” Fichier existe: {os.path.exists(status_path)}")
                
                if os.path.exists(status_path):
                    self.send_response(200)
                    self.send_header('Content-type', 'application/json')
                    self.end_headers()
                    with open(status_path, 'rb') as f:
                        self.wfile.write(f.read())
                    print(f"âœ… status.json servi avec succÃ¨s")
                    return
                else:
                    # Essayer aussi /app/status.json au cas oÃ¹
                    alt_path = '/app/status.json'
                    if os.path.exists(alt_path):
                        self.send_response(200)
                        self.send_header('Content-type', 'application/json')
                        self.end_headers()
                        with open(alt_path, 'rb') as f:
                            self.wfile.write(f.read())
                        print(f"âœ… status.json servi depuis {alt_path}")
                        return
                    else:
                        self.send_response(404)
                        self.send_header('Content-type', 'application/json')
                        self.end_headers()
                        error_msg = json.dumps({"error": "status.json not found", "cwd": os.getcwd(), "paths_checked": [status_path, alt_path]})
                        self.wfile.write(error_msg.encode('utf-8'))
                        print(f"âŒ status.json non trouvÃ©. CWD: {os.getcwd()}")
                        return
            
            # GÃ©rer les routes sans extension (comme /admin)
            if self.path == '/admin' or self.path == '/admin/':
                self.path = '/admin.html'
            
            # Sinon, servir depuis le dossier Site
            return super().do_GET()
        
        def do_POST(self):
            # Si c'est une requÃªte API, proxy vers Flask
            if self.path.startswith('/api/'):
                self._proxy_to_flask('POST')
                return
            
            # Sinon, 404
            self.send_response(404)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            error_msg = json.dumps({"error": "Not found"})
            self.wfile.write(error_msg.encode('utf-8'))
        
        def do_DELETE(self):
            # Si c'est une requÃªte API, proxy vers Flask
            if self.path.startswith('/api/'):
                self._proxy_to_flask('DELETE')
                return
            
            # Sinon, 404
            self.send_response(404)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            error_msg = json.dumps({"error": "Not found"})
            self.wfile.write(error_msg.encode('utf-8'))
        
        def log_message(self, format, *args):
            # RÃ©duire les logs verbeux
            pass
    
    server = HTTPServer(('0.0.0.0', port), CustomHandler)
    log(f"ğŸŒ Serveur web dÃ©marrÃ© sur le port {port}", 'success')
    log(f"ğŸ“± Site accessible sur http://localhost:{port}/index.html", 'info')
    server.serve_forever()

# Lancer le serveur web en arriÃ¨re-plan
threading.Thread(target=start_web_server, daemon=True).start()

log("ğŸš€ Bot PSM dÃ©marrÃ© avec serveur web intÃ©grÃ©!", 'success')

# âœ… BOUCLE PRINCIPALE MULTI-MATCHS
while True:
    MATCHS = charger_matchs()  # Recharger les matchs Ã  chaque itÃ©ration
    log(f"ğŸ“‹ Cycle de surveillance: {len(MATCHS)} match(s) Ã  vÃ©rifier", 'info')
    if len(MATCHS) > 0:
        matchs_noms = ', '.join([m['nom'] for m in MATCHS])
        log(f"ğŸ“ Matchs: {matchs_noms}", 'info')
    for match in MATCHS:
        verifier_match(match)

    pause = 90 + random.randint(0, 5)
    log(f"â³ Pause {pause} secondes...", 'info')
    time.sleep(pause)


